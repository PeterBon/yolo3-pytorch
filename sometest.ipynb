{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from utils.augment import DataAugmentForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/tt100k/test_new'\n",
    "image_path = os.path.join(path,'3236.jpg')\n",
    "annotations_path = os.path.join(path,'annotations.json')\n",
    "image_id = '3236'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132 480 167 519  71]\n",
      " [170 481 202 515  91]\n",
      " [204 481 240 516  22]\n",
      " [242 481 278 517 108]\n",
      " [687 523 712 556  71]]\n",
      "(5, 5)\n",
      "[[132, 480, 167, 519], [170, 481, 202, 515], [204, 481, 240, 516], [242, 481, 278, 517], [687, 523, 712, 556]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "annotations = json.loads(open(annotations_path).read())\n",
    "types = annotations['types']\n",
    "labels = []\n",
    "for obj in annotations['imgs'][image_id]['objects']:\n",
    "    category = obj['category']\n",
    "    category_id = types.index(category)\n",
    "    xmin = int(obj['bbox']['xmin'])\n",
    "    ymin = int(obj['bbox']['ymin'])\n",
    "    xmax = int(obj['bbox']['xmax'])\n",
    "    ymax = int(obj['bbox']['ymax'])\n",
    "    label = [xmin,ymin,xmax,ymax,category_id]\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "bboxes = labels[:,:4].tolist()\n",
    "print(bboxes)\n",
    "print(len(bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n",
      "5\n",
      "[[128, 136, 138, 147], [139, 137, 148, 146], [149, 137, 159, 147], [159, 137, 170, 147], [286, 149, 293, 158]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image_path)\n",
    "aug = DataAugmentForObjectDetection()\n",
    "img_new,bboxes_new = aug.letterbox(img,bboxes)\n",
    "print(img_new.shape)\n",
    "print(len(bboxes_new))\n",
    "print(bboxes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bbox in bboxes_new:\n",
    "    x_min = bbox[0]\n",
    "    y_min = bbox[1]\n",
    "    x_max = bbox[2]\n",
    "    y_max = bbox[3]\n",
    "    draw = cv2.rectangle(img_new,(int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('pic', 0)  # 1表示原图\n",
    "cv2.moveWindow('pic', 0, 0)\n",
    "cv2.resizeWindow('pic', 800, 800)  # 可视化的图片大小\n",
    "cv2.imshow('pic', draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "a = np.array(list)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "b = Variable(torch.from_numpy(a).type(torch.FloatTensor))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(0):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = '10056.jpg'\n",
    "line=str.split()\n",
    "# box = np.array([np.array(list(map(int, box.split(',')))) for box in line[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in line[1:]:\n",
    "    box.split(',')\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import random_crop,random_perspective,letterbox,augment_hsv,box_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image,bboxes):\n",
    "    for bbox in bboxes:\n",
    "        x_min = bbox[0]\n",
    "        y_min = bbox[1]\n",
    "        x_max = bbox[2]\n",
    "        y_max = bbox[3]\n",
    "        draw = cv2.rectangle(image,(int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 1)\n",
    "    cv2.namedWindow('pic', 0)  # 1表示原图\n",
    "    cv2.moveWindow('pic', 0, 0)\n",
    "    cv2.resizeWindow('pic', 800, 800)  # 可视化的图片大小\n",
    "    cv2.imshow('pic', draw)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tt100k_train.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Peter/PycharmProjects/datasets/tt100k\\train/10009.jpg 1296,932,1319,957,4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1296  932 1319  957    4]]\n",
      "[[1296  932 1319  957]]\n",
      "[[4]]\n"
     ]
    }
   ],
   "source": [
    "line = lines[0].split()\n",
    "image = cv2.imread(line[1])\n",
    "targets = np.array([np.array(list(map(int, box.split(',')))) for box in line[1:]])  # xyxy,cls\n",
    "n = len(targets)\n",
    "bboxes = targets[:, :4]\n",
    "cls = targets[:, -1].reshape(n,1)\n",
    "print(targets)\n",
    "print(bboxes)\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2d368dd08c50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1、随机裁剪，更新image、bboxes和targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_crop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\yolo3-pytorch\\utils\\dataloader.py\u001b[0m in \u001b[0;36mrandom_crop\u001b[1;34m(image, bboxes)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# ---------------------- 裁剪图像 ----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# 找到刚好包含所有box的框\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mmax_bbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 1、随机裁剪，更新image、bboxes和targets\n",
    "image, bboxes = random_crop(image, bboxes)\n",
    "draw(image,bboxes)\n",
    "targets = np.concatenate((cls,bboxes),axis = 1)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1、随机裁剪，更新image、bboxes和targets\n",
    "image, bboxes = random_crop(image, bboxes)\n",
    "targets = np.concatenate((cls, bboxes), axis=1)\n",
    "\n",
    "# 2、letterbox，输出416x416\n",
    "image, targets = letterbox(image, targets, new_shape=input_shape)\n",
    "\n",
    "# 3、随机透视变换\n",
    "image, targets = random_perspective(image, targets)\n",
    "\n",
    "# 4、色域变换\n",
    "augment_hsv(image, hgain=hgain, sgain=sgain, vgain=vgain)\n",
    "\n",
    "# 5、targets由cls,xyxy转为xyxy,cls\n",
    "cls = targets[:, 0]\n",
    "bboxes = targets[:, 1:5]\n",
    "targets = np.concatenate((bboxes, cls), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
